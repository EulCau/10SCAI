\documentclass[aspectratio=169]{beamer}
\usetheme{Madrid}
\usefonttheme[onlymath]{serif}
\usepackage{ctex, amsmath, amsfonts, amssymb}
\usepackage{graphicx}

\def\dif{\mathinner{\mathrm{d}}\hphantom{\mskip-\thinmuskip}}

\title{高维 PDE 求解算法：\\从非线性蒙特卡罗到机器学习}
\author{Weinan E \and Jiequn Han \and Arnulf Jentzen}
\date{2020年9月14日}

\begin{document}

	\begin{frame}
		\titlepage
	\end{frame}

	\begin{frame}{大纲}
		\tableofcontents
	\end{frame}

	\section{引言与背景}
	\begin{frame}{引言与背景}
		\begin{itemize}
			\item 高维偏微分方程 (PDEs) 在控制理论, 金融工程, 量子力学等领域有重要应用
			\item 传统数值方法 (如有限差分、有限元) 在高维情况下受``维数灾难''限制
			\item 本论文提出利用非线性蒙特卡罗方法和深度学习技术求解高维 PDE, 从而突破维数灾难
		\end{itemize}
	\end{frame}

	\section{主要方法与技术}
	\begin{frame}{深度 BSDE 方法 (Deep BSDE)}
		\begin{itemize}
			\item 将非线性抛物型 PDE
				\begin{equation*}
					\frac{\partial u}{\partial t} + \frac{1}{2} \mathrm{Tr}\left(\sigma\sigma^{\top}\,\mathrm{Hess}_x u\right) + \langle\nabla u, \mu\rangle + f\left(t, x, u, \sigma^{\top} \nabla u\right)=0, \quad u\left(T,x\right)=g\left(x\right)
				\end{equation*}
				与后向随机微分方程 (BSDE) 联系起来
			\item 通过 It\^{o} 引理可得:
				\begin{equation*}
					\begin{aligned}
						u\left(t, X_{t}\right) - u\left(0, X_{0}\right) = &-\int_{0}^{t} f\left(s, X_{s}, u\left(s, X_s\right), \sigma^{\top}\nabla u\left(s, X_{s}\right)\right) \dif s \\
						&+ \int_{0}^{t} \left(\nabla u\left(s, X_{s}\right)\right)^{\top}\sigma(s, X_{s}) \dif W_{s}.
					\end{aligned}
				\end{equation*}
		\end{itemize}
	\end{frame}

	\subsection{深度 BSDE 方法 (Deep BSDE)}
	\begin{frame}{深度 BSDE 方法 (Deep BSDE)}
		\begin{itemize}
			\item Pardoux 和 Peng 提出如果令 $Y_{t} = u\left(t, X_{t}\right), Z_{t} = \left[\sigma\left(t, X_{t}\right)\right]^{\top} \left(\nabla_{x} u \right)\left(t, X_{t}\right)$, 则随机过程 $\left(X_{t}, Y_{t}, Z_{t}\right) \in \mathbb{R}^{d} \times \mathbb{R} \times \mathbb{R}^d, t \in \left[0, T\right]$, 满足下面的 BSDE:
				\begin{equation*}
					\left\{\begin{array}{l}
						X_{t} = \xi + \int_{0}^{t} \mu\left(s, X_{s}\right) \dif s + \int_{0}^{t} \sigma\left(s, X_{s}\right) \dif W_{s} \\
						Y_{t} = g\left(X_{T}\right) + \int_{t}^{T} f\left(s, X_{s}, Y_{s}, Z_{s}\right) \dif s - \int_{t}^{T} \left(Z_{s}\right)^{\top} \dif W_{s}
					\end{array}\right.
				\end{equation*}
			\item 利用深度神经网络逼近未知函数: 例如用网络 $\psi_{0}$ 表示 $u(0, X_{0})$, 用子网络 $\phi_{n}$ 逼近 $Z_{t}$. 通过离散化时间构建网络, 将末端误差作为损失函数进行训练.
		\end{itemize}
	\end{frame}

	\begin{frame}{深度 BSDE 方法 (Deep BSDE)}
		\begin{itemize}
			\item 问题最终转化为
				\begin{align}
					\inf_{\psi_{0}, \left\{\phi_{n}\right\}_{n=0}^{N-1}} & \mathbb{E} \left\lvert g\left(X_{T}\right) - Y_{T}\right\rvert^{2}, \\
					s.t.\quad & X_{0} = \xi, \quad Y_{0} = \psi_{0}\left(\xi\right), \\
					& X_{t_{n+1}} = X_{t_{i}} + \mu\left(t_{n},X_{t_{n}}\right) \Delta t + \sigma\left(t_{n},X_{t_{n}}\right) \Delta W_{n}, \\
					& Z_{t_{n}} = \phi_{n}\left(X_{t_{n}}\right), \\
					& Y_{t_{n+1}} = Y_{t_{n}} - f\left(t_{n}, X_{t_{n}}, Y_{t_{n}}, Z_{t_{n}}\right) \Delta t + \left(Z_{t_{n}}\right)^{\top} \Delta W_{n}
				\end{align}
			\item 取误差函数为
				\begin{equation*}
					l\left(\theta\right) = \mathbb{E}\left[\left\lvert g\left(X_{t_{N}}\right) - \hat{u}\left(\left\{X_{t_{n}}\right\}_{0 \leq n \leq N}, \left\{W_{t_{n}}\right\}_{0 \leq n \leq N}\right)\right\rvert^2\right].
				\end{equation*}
				其中 $\hat{u}\left(\left\{X_{t_{n}}\right\}_{0 \leq n \leq N}, \left\{W_{t_{n}}\right\}_{0 \leq n \leq N}\right)$ 为网络的最后一个输出, 为 $u\left(t_{N}, X_{t_{N}}\right)$ 的近似
		\end{itemize}

	\end{frame}

	\iffalse
	\subsection{多层皮卡德方法 (MLP)}
	\begin{frame}{多层皮卡德方法 (MLP)}
		\begin{itemize}
			\item 针对半线性热方程
				\begin{equation*}
				\frac{\partial u}{\partial t}(t,x)=\Delta u(t,x)+f(u(t,x))
				\end{equation*}
			\item 将 PDE 写成不动点形式 \(u = \Phi(u)\)，并构造 Picard 迭代
				\begin{equation*}
				u_n = \Phi(0) + \sum_{l=1}^{n-1} \bigl[\Phi(u_l)-\Phi(u_{l-1})\bigr].
				\end{equation*}
			\item 利用多层次蒙特卡罗采样逼近期望值，每层使用不同精度的蒙特卡罗估计
			\item 理论证明：在一定条件下，计算复杂度仅呈多项式增长，克服了维数灾难问题
		\end{itemize}
	\end{frame}

	\subsection{传统方法与神经网络结合}
	\begin{frame}{传统方法与神经网络结合}
		\begin{itemize}
			\item 利用 Ritz、Galerkin 以及最小二乘方法构造数值方案
			\item 例如，深度 Ritz 方法将问题转化为求解变分问题：
				\begin{equation*}
				\min_{u\in H} I(u),\quad I(u)=\int_\Omega \Bigl(\frac{1}{2}|\nabla u(x)|^2 - f(x)u(x)\Bigr)dx.
				\end{equation*}
			\item 通过神经网络表示试探函数，实现无网格（mesh-free）的近似，具有自然的自适应性
		\end{itemize}
	\end{frame}
	\fi

	\section{高维控制问题}
	\begin{frame}{高维控制问题}
		\begin{itemize}
			\item 传统控制理论中, 最优控制问题的解往往受到维数灾难的限制
			\item 我们考虑下面的最优控制问题:
				\begin{equation*}
					\min_{u} g\left(x\left(T\right)\right) + \int_{0}^{T} L\left(t, x\left(t\right), u\left(t, x\left(t\right)\right)\right) \dif t
				\end{equation*}
				受限于动态系统
				\begin{equation*}
					\dot{x} = f\left(t, x, u\right) \quad x\left(0\right) = x_{0}
				\end{equation*}
			\item 对于开环控制, 仅沿最优路径定义控制函数 $u\left(t, x\right) = u^{*}\left(t, x^{*}\left(t\right)\right)$. 其自变量仅为时间, 维数灾难并不是主要问题
			\item 对于闭环控制, 控制函数 $u\left(t, x\right) = u^{*}\left(t, x\right)$ 在全局状态空间定义, 维数灾难成为主要问题
		\end{itemize}
	\end{frame}

	\begin{frame}{高维控制问题}
		\begin{itemize}
			\item Pontryagin 极小原理给出了最优控制问题的理论基础
			\item 令扩展哈密顿量为 $\tilde{H} = L + \lambda^{\top} f$, $u^{*}\left(t, x; \lambda\right) = \arg\min_{u\in U} \tilde{H}\left(t, x, \lambda, u\right)$ 则由 Pontryagin 极小原理, 下面的方程组有解
				\begin{equation*}
					\left\{
						\begin{array}{ll}
							\left.\dot{x} = \tilde{H}_{\lambda}\right|_{u = u^{*}}	& x\left(0\right) = x_{0}										\\
							\left.\dot{\lambda} = -\tilde{H}_{x}\right|_{u = u^{*}}	& \lambda\left(T\right) = \nabla g\left(x\left(T\right)\right)	\\
							\left.\dot{v} = -L\right|_{u = u^{*}}											& v\left(T\right) = g\left(x\left(T\right)\right)
						\end{array}
					\right.
				\end{equation*}
				其中, $x$ 为状态变量, $\lambda$ 为伴随变量, $\tilde{H}$ 为 Hamilton 函数
		\end{itemize}
	\end{frame}

	\begin{frame}{高维控制问题}
		\begin{itemize}
			\item 记
				\begin{equation*}
					V\left(t, x\right) = \inf_{u \in U}\{g\left(y\left(T\right)\right) + \int_{t}^{T}L\left(\tau, y, u\right) \dif \tau\}
				\end{equation*}
				其中 $\dot{y}\left(\tau\right) = f\left(\tau, y, u\right), y\left(t\right) = x$,
				\begin{equation*}
					H^{*}\left(t, x, \lambda\right) = \tilde{H}\left(t, x, \lambda, u^{*}\left(t, x; \lambda\right)\right)
				\end{equation*}
				则 $V$ 满足 HJB 方程 $V_{t} + H^{*}\left(t, x, V_{x}\right) = 0$, 且有终端条件 $V\left(T, x\right) = g\left(x\right)$ 通过数值方法求解 HJB 方程, 可以得到最优控制函数 $u^{*}$
		\end{itemize}
	\end{frame}

	\begin{frame}{高维控制问题}
		\begin{itemize}
			\item 想通过机器学习方法求解高维控制问题, 需要推广到所有初值条件. 于是考虑如下问题
				\begin{equation*}
					\min_{u} \mathbb{E}_{x_{0}\sim\mu}\left[g\left(x\left(T\right)\right) + \int_{0}^{T} L\left(t, x\left(t\right), u\left(t, x\left(t\right)\right)\right) \dif t \right]
				\end{equation*}
				\begin{equation*}
					\dot{x} = f\left(t, x, u\right),\quad x\left(0\right) = x_{0},\quad \mu = \frac{1}{Z}e^{-\beta V}
				\end{equation*}
			\item 为解决数据生成问题, 需要采用如下策略:
				\begin{enumerate}
					\item 求解前面的两点边值问题来生成训练数据
					\item 利用生成的数据训练神经网络, 以逼近值函数 $V$ 和最优控制函数 $u^{*}$
				\end{enumerate}
			\item 然而, 这个两点边值问题的求解也不简单, 具体可以采用 ``热启动'' 策略或者自适应采样方法.
		\end{itemize}
	\end{frame}

	\iffalse
	\begin{frame}{Deep Learning Approach for Control}
		\textbf{策略函数参数化}：
		\[
		a_t(s_t) \approx a_t(s_t|\theta_t) \quad (\text{神经网络近似})
		\]

		\textbf{损失函数}：
		\[
		L(\{\theta_t\}) = \mathbb{E}\left[ \sum_{t=0}^{T-1} c_t(s_t,a_t) + c_T(s_T) \right]
		\]

		\textbf{关键创新}：
		\begin{itemize}
			\item 使用SGD优化高维策略空间
			\item 自适应采样技术选择训练数据
			\item "Warm start"初始化提升收敛性
		\end{itemize}
	\end{frame}

	\section{Chapter 5: Ritz, Galerkin \& Least Squares}
	\begin{frame}{Deep Ritz Method}
		\textbf{变分问题}：
		\[
		\min_{u \in H} \int_\Omega \left( \frac{1}{2}|\nabla u|^2 - fu \right) dx
		\]

		\textbf{实现步骤}：
		\begin{enumerate}
			\item 用DNN参数化$u(x;\theta)$
			\item 蒙特卡洛离散积分：
			\[
			I(u) \approx \frac{1}{N}\sum_{i=1}^N \left( \frac{1}{2}|\nabla u(x_i)|^2 - f(x_i)u(x_i) \right)
			\]
			\item 添加边界惩罚项：
			\[
			L(\theta) = I(u_\theta) + \beta \int_{\partial\Omega} u_\theta^2 ds
			\]
		\end{enumerate}
	\end{frame}

	\begin{frame}{Comparison of Methods}
		\begin{table}[ht]
		\centering
		\begin{tabular}{|l|l|l|}
		\hline
		\textbf{方法} & \textbf{基础} & \textbf{挑战} \\
		\hline
		Ritz & 变分原理 & 边界条件处理 \\
		Galerkin & 弱形式 & 测试函数选择 \\
		Least Square & 残差最小化 & 条件数恶化 \\
		\hline
		\end{tabular}
		\end{table}

		\textbf{Galerkin与WGAN的类比}：
		\[
		\min_G \max_D \left| \mathbb{E}[\phi(G(z))] - \mathbb{E}[\phi(x)] \right|
		\]
		生成器$G$对应试函数，判别器$D$对应测试函数
	\end{frame}

	\section{Chapter 6: Multilevel Picard Methods}
	\begin{frame}{MLP核心思想}
		\textbf{三步法}：
		\begin{enumerate}
			\item PDE转化为随机固定点方程：
			\[
			u(t,x) = \mathbb{E}\left[ u(0,x+\sqrt{2}W_t) + \int_0^t f(u(s,x+W_{t-s}))ds \right]
			\]
			\item Picard迭代：
			\[
			u_{n} = \Phi(u_{n-1})
			\]
			\item 多级蒙特卡洛近似：
			\[
			U_{n,M}^{d,\theta} = \sum_{k=1}^{n-1} \frac{t}{M^{n-k}} \sum_{m=1}^{M^{n-k}} [f(U_k) - f(U_{k-1})] 
			\]
		\end{enumerate}
	\end{frame}

	\begin{frame}{复杂度分析}
		\textbf{定理3的核心结论}：
		\begin{itemize}
			\item 计算复杂度：$\mathcal{C} \leq cd^c \varepsilon^{-3}$
			\item 逼近误差：$\mathbb{E}[|U_{\mathfrak{N}_\varepsilon}(T,0)-u_d(T,0)|^2]^{1/2} \leq \varepsilon$
		\end{itemize}

		\textbf{关键创新点}：
		\begin{itemize}
			\item 全历史递归结构避免维数灾难
			\item 多级精度采样平衡误差与计算量
			\item 适用于半线性抛物型PDE的广泛类别
		\end{itemize}

		\begin{exampleblock}{优势对比}
		传统蒙特卡洛：$\mathcal{O}(e^d)$ vs MLP：$\mathcal{O}(d^c)$
		\end{exampleblock}
	\end{frame}

	\section{Key Derivations}
	\begin{frame}{From PDE to Stochastic Fixed Point}
		\textbf{半线性热方程}：
		\[
		\partial_t u = \Delta u + f(u)
		\]

		\textbf{Feynman-Kac公式推广}：
		\[
		u(t,x) = \mathbb{E}\left[ u(0,x+\sqrt{2}W_t) + \int_0^t f(u(s,x+\sqrt{2}W_{t-s}))ds \right]
		\]

		\textbf{证明思路}：
		\begin{enumerate}
			\item 应用Ito公式于$u(t,X_t)$
			\item 利用BSDE理论建立对应关系
			\item 构造压缩映射$\Phi$保证收敛性
		\end{enumerate}
	\end{frame}

	\begin{frame}{MLP Approximation Construction}
		\textbf{递归展开}：
		\[
		u_n = \Phi(u_{n-1}) = \Phi(0) + \sum_{k=1}^{n-1} [\Phi(u_k) - \Phi(u_{k-1})]
		\]

		\textbf{多级展开示意图}：
		% figure
	\end{frame}
	\fi

	\iffalse
	\section{数学公式解析}
	\begin{frame}{关键数学公式解析}
		\begin{itemize}
			\item \textbf{Hamilton-Jacobi-Bellman (HJB) 方程:}
				\begin{equation*}
				\frac{\partial u}{\partial t}+H(x,\nabla u)=0.
				\end{equation*}
				描述最优控制问题中价值函数的动态规划原理
			\item \textbf{Black-Scholes 方程:}
				\begin{equation*}
				\frac{\partial u}{\partial t}+\frac{1}{2}\sigma^2 \sum_{i=1}^{d}x_i^2 \frac{\partial^2 u}{\partial x_i^2}+r\langle \nabla u,x\rangle-ru+f(u)=0.
				\end{equation*}
				用于金融衍生品定价，考虑违约风险、交易成本等非线性效应
			\item \textbf{蒙特卡罗积分:}
				\begin{equation*}
				I(g)=\int_{[0,1]^d}g(x)dx,\quad I_n(g)=\frac{1}{n}\sum_{j=1}^n g(x_j),
				\end{equation*}
				误差分析：
				\begin{equation*}
				\mathbb{E}\Bigl[|I(g)-I_n(g)|^2\Bigr]=\frac{\mathrm{Var}(g)}{n}.
				\end{equation*}
			\item \textbf{神经网络近似表达式:}
				\begin{equation*}
				f_m(x,\theta)=\frac{1}{m}\sum_{j=1}^{m}a_j\,\sigma\bigl(\langle w_j,x\rangle\bigr),
				\end{equation*}
				以及 ResNet 形式：
				\begin{equation*}
				z_{l+1}=z_l+\frac{1}{L}\sum_{j=1}^{M}a_{j,l}\,\sigma\bigl(\langle z_l,w_{j,l}\rangle\bigr).
				\end{equation*}
		\end{itemize}
	\end{frame}
	\fi

	\section{结论与未来展望}
	\begin{frame}{结论与未来展望}
		\begin{itemize}
			\item 利用非线性蒙特卡罗和深度学习方法，设计出不受维数灾难影响的高效数值算法
			\item 理论与数值实验均证明：对于控制、金融、量子等领域的高维问题，这些方法具有显著优势
			\item 未来工作：进一步完善理论证明、改进算法效率以及扩展到更广泛的应用场景
		\end{itemize}
	\end{frame}

	\begin{frame}{参考文献}
		\begin{itemize}
			\item Weinan E, Jiequn Han, Arnulf Jentzen. \emph{Algorithms for Solving High Dimensional PDEs: From Nonlinear Monte Carlo to Machine Learning}, 2020.
			\item 其他相关文献……
		\end{itemize}
	\end{frame}

	\begin{frame}
		\centering \Large 谢谢大家！
	\end{frame}

\end{document}
